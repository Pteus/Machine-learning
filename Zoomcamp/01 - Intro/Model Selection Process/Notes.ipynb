{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c262015",
   "metadata": {},
   "source": [
    "# Model Selection Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6442638a",
   "metadata": {},
   "source": [
    "### Model Performance on New Data\n",
    "\n",
    "Imagine there is a model $g$ and a dataset $X$ with target values $y$. The model performs quite well on this data. However, new data becomes available, and you want to assess how well the model performs on this new data. One approach is to use a train-validation split:\n",
    "\n",
    "1. **Train-Validation Split:**\n",
    "   - Split the entire dataset into two parts:\n",
    "     - **Training Set (80%)**: Use the old dataset to train the model.\n",
    "     - **Validation Set (20%)**: Use the new dataset to validate the model.\n",
    "     \n",
    "   This method allows you to evaluate the model's performance on unseen data, providing a better understanding of how it generalizes to new information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce3f2b9",
   "metadata": {},
   "source": [
    "### Steps to Get Model Performance\n",
    "\n",
    "1. **Extract Feature Matrix and Target Values:**\n",
    "   - Extract the feature matrix $ \\mathbf{X}_{\\text{train}} $ from the training dataset.\n",
    "   - Obtain the target values $ \\mathbf{y}_{\\text{train}} $ from the training dataset.\n",
    "\n",
    "2. **Train the Model:**\n",
    "   - Use $ \\mathbf{X}_{\\text{train}} $ and $ \\mathbf{y}_{\\text{train}} $ to train the model $ g $.\n",
    "\n",
    "3. **Prepare Validation Data:**\n",
    "   - From the validation dataset, obtain the feature matrix $ \\mathbf{X}_{\\text{V}} $ and the target values $ \\mathbf{y}_{\\text{V}} $.\n",
    "\n",
    "4. **Predict Using the Model:**\n",
    "   - Apply the model $ g $ to $ \\mathbf{X}_{\\text{V}} $ to get predicted values: $ g(\\mathbf{X}_{\\text{V}}) = \\hat{\\mathbf{y}}_{\\text{V}} $.\n",
    "\n",
    "5. **Evaluate Model Performance:**\n",
    "   - Compare the predicted values $ \\hat{\\mathbf{y}}_{\\text{V}} $ with the actual values $ \\mathbf{y}_{\\text{V}} $ to assess model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a2a8ad",
   "metadata": {},
   "source": [
    "Let's assume that  $ \\hat{\\mathbf{y}}_{\\text{V}} > 0.5 $ is 1 and $ \\hat{\\mathbf{y}}_{\\text{V}} < 0.5 $ is 0, call it \"Prediction\"\n",
    "\n",
    "\\[\n",
    "\\begin{array}{ccc}\n",
    "\\hat{y}_V & \\text{Prediction} & y_V \\\\\n",
    "\\hline\n",
    "0.8 & 1 & 1 \\\\\n",
    "0.7 & 1 & 0 \\\\\n",
    "0.6 & 1 & 1 \\\\\n",
    "0.1 & 0 & 0 \\\\\n",
    "0.9 & 1 & 1 \\\\\n",
    "0.6 & 1 & 0 \\\\\n",
    "\\end{array}\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8002fcb7",
   "metadata": {},
   "source": [
    "4 of 6 predicted values are correct ~ 66% accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005901cf",
   "metadata": {},
   "source": [
    "### Model Comparison and Selection\n",
    "\n",
    "After trying different models, the following accuracies were obtained:\n",
    "\n",
    "- **g1**: Linear Regression - 66%\n",
    "- **g2**: Decision Tree - 60%\n",
    "- **g3**: Random Forest - 67%\n",
    "- **g4**: Neural Network - 80%\n",
    "\n",
    "Based on these results, **g4 (Neural Network)** achieved the highest accuracy of 80%, making it the best model for this task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c861bd4",
   "metadata": {},
   "source": [
    "### Multiple Comparison Problem and Training-Validation-Test Split\n",
    "\n",
    "When comparing different models on a single validation dataset, there is a risk that the winning model could perform well due to luck, similar to a coin-flip scenario. To mitigate this, it's recommended to split your dataset into three parts: training, validation, and test sets (60%-20%-20%).\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "1. **Dataset Splitting:**\n",
    "   - Split your dataset into:\n",
    "     - **Training Set (60%)**: Used for training the models.\n",
    "     - **Validation Set (20%)**: Used for model selection and hyperparameter tuning.\n",
    "     - **Test Set (20%)**: Held out completely until the final evaluation.\n",
    "\n",
    "2. **Model Selection:**\n",
    "   - Train multiple models using the training set and evaluate their performance on the validation set.\n",
    "   - Select the best-performing model based on the validation set results.\n",
    "\n",
    "3. **Final Evaluation:**\n",
    "   - Apply the selected model to the test set to evaluate its performance:\n",
    "     - $ g(X_T) = y_T $\n",
    "\n",
    "#### Example Results:\n",
    "\n",
    "| Model | Type | Accuracy (Validation) | Accuracy (Test) |\n",
    "|-------|------|-----------------------|-----------------|\n",
    "| g1    | Linear Regression      | 66%                   | -               |\n",
    "| g2    | Decision Tree          | 60%                   | -               |\n",
    "| g3    | Random Forest          | 67%                   | -               |\n",
    "| g4    | Neural Network         | 80%                   | 79%             |\n",
    "\n",
    "Based on these results, **g4 (Neural Network)** achieved high accuracy not only on the validation set (80%) but also maintained strong performance on the test set (79%). This consistency suggests that g4's performance is robust and not merely a result of luck on the validation dataset.\n",
    "\n",
    "By following this approach, we can confidently conclude that g4 behaves consistently well across both validation and test datasets, making it a reliable choice for this task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372ce9e4",
   "metadata": {},
   "source": [
    "### Steps for Model Training and Evaluation\n",
    "\n",
    "1. **Split Datasets (60%-20%-20%):**\n",
    "   - Divide the dataset into three parts:\n",
    "     - **Training Set (60%)**: Used to train the models.\n",
    "     - **Validation Set (20%)**: Used to select the best model and tune hyperparameters.\n",
    "     - **Test Set (20%)**: Held out until the final evaluation.\n",
    "\n",
    "2. **Train the Model:**\n",
    "   - Train multiple models using the training set.\n",
    "\n",
    "3. **Apply the Model to Validation Dataset:**\n",
    "   - Evaluate each trained model using the validation set.\n",
    "\n",
    "4. **Repeat Steps 2 and 3 a Few Times:**\n",
    "   - Iterate the training and evaluation process to fine-tune models and improve performance.\n",
    "\n",
    "5. **Select the Best Model:**\n",
    "   - Based on performance metrics on the validation set, select the model with the highest accuracy or best performance.\n",
    "\n",
    "6. **Apply the Model to the Test Dataset:**\n",
    "   - Use the selected model to make predictions on the test set for final evaluation.\n",
    "\n",
    "7. **Check Everything Is Good (Compare Accuracy of Validation and Test Datasets):**\n",
    "   - Compare the model's performance metrics (e.g., accuracy) on the validation and test datasets to ensure consistency and reliability.\n",
    "\n",
    "By following these steps, you ensure that the selected model performs well not only on the validation dataset but also on unseen data from the test dataset, thereby validating its generalizability and robustness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc682602",
   "metadata": {},
   "source": [
    "### Alternative Approach\n",
    "This approach uses the validation (plus the training dataset) dataset to retrain the model.\n",
    "\n",
    "\n",
    "1. **Data Splitting (60%-20%-20%):**\n",
    "   - Split the original dataset into three parts:\n",
    "     - **Training Set (60%)**: Used to train initial models.\n",
    "     - **Validation Set (20%)**: Used to select the best-performing model.\n",
    "     - **Test Set (20%)**: Held out until final evaluation for unbiased performance assessment.\n",
    "\n",
    "2. **Initial Model Training:**\n",
    "   - Train multiple models using the training dataset.\n",
    "\n",
    "3. **Validation Phase:**\n",
    "   - Apply each initial model to the validation set to evaluate their performance metrics (e.g., accuracy, F1 score).\n",
    "\n",
    "4. **Model Selection:**\n",
    "   - Select the best-performing model based on validation set results.\n",
    "\n",
    "5. **Combined Dataset Creation:**\n",
    "   - Combine the training and validation datasets to create a new combined dataset for retraining.\n",
    "\n",
    "6. **Retraining the Model:**\n",
    "   - Retrain the selected model using the new combined dataset to improve its performance.\n",
    "\n",
    "7. **Final Evaluation:**\n",
    "   - Apply the retrained model to the test set to assess its performance on unseen data.\n",
    "\n",
    "By following this approach, you ensure thorough evaluation and enhancement of the model's performance through iterative training on combined datasets and unbiased evaluation on the test set. This method enhances the model's generalizability and effectiveness in real-world applications.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
